{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## import libs"
      ],
      "metadata": {
        "id": "9FYswat-GqMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate \n",
        "from tensorflow.keras.layers import Input, Add, Conv2DTranspose\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanSquaredError, BinaryCrossentropy\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import callbacks\n",
        "\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from IPython.display import clear_output\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode"
      ],
      "metadata": {
        "id": "70XjOYlsDRSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount to Google Drive"
      ],
      "metadata": {
        "id": "KMqH0IwsGs-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "qhH5EuAaBi9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/GoogleColab/FCN"
      ],
      "metadata": {
        "id": "2RolJp2RBmj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "QVrEx34nBnlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model and dataset\n"
      ],
      "metadata": {
        "id": "rhn-nJVPGwT-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9lb15fUBhHp"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model('saved_model/my_model')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load directories\n",
        "train_data_dir = \"input/training/image_2/\"\n",
        "train_gt_dir = \"input/training/gt_image_2/\"\n",
        "\n",
        "test_data_dir = \"input/testing/\""
      ],
      "metadata": {
        "id": "-_mBIeKADlD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of training examples\n",
        "TRAINSET_SIZE = int(len(os.listdir(train_data_dir)) * 0.8)\n",
        "print(f\"Number of Training Examples: {TRAINSET_SIZE}\")\n",
        "\n",
        "VALIDSET_SIZE = int(len(os.listdir(train_data_dir)) * 0.1)\n",
        "print(f\"Number of Validation Examples: {VALIDSET_SIZE}\")\n",
        "\n",
        "TESTSET_SIZE = int(len(os.listdir(train_data_dir)) - TRAINSET_SIZE - VALIDSET_SIZE)\n",
        "print(f\"Number of Testing Examples: {TESTSET_SIZE}\")"
      ],
      "metadata": {
        "id": "kMVhzwcHDm1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Constants\n",
        "IMG_SIZE = 128\n",
        "N_CHANNELS = 3\n",
        "N_CLASSES = 1\n",
        "SEED = 123"
      ],
      "metadata": {
        "id": "fE6Vu8UqDoVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load image and return a dictionary\n",
        "def parse_image(img_path: str) -> dict:\n",
        "    image = tf.io.read_file(img_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "\n",
        "    # Three types of img paths: um, umm, uu\n",
        "    # gt image paths: um_road, umm_road, uu_road\n",
        "    mask_path = tf.strings.regex_replace(img_path, \"image_2\", \"gt_image_2\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"um_\", \"um_road_\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"umm_\", \"umm_road_\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"uu_\", \"uu_road_\")\n",
        "    \n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=3)\n",
        "    \n",
        "    non_road_label = np.array([255, 0, 0])\n",
        "    road_label = np.array([255, 0, 255])\n",
        "    other_road_label = np.array([0, 0, 0])\n",
        "    \n",
        "    # Convert to mask to binary mask\n",
        "    mask = tf.experimental.numpy.all(mask == road_label, axis = 2)\n",
        "    mask = tf.cast(mask, tf.uint8)\n",
        "    mask = tf.expand_dims(mask, axis=-1)\n",
        "\n",
        "    return {'image': image, 'segmentation_mask': mask}"
      ],
      "metadata": {
        "id": "t4-58c48DyXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dataset variables\n",
        "all_dataset = tf.data.Dataset.list_files(train_data_dir + \"*.png\", seed=SEED)\n",
        "all_dataset = all_dataset.map(parse_image)\n",
        "\n",
        "train_dataset = all_dataset.take(TRAINSET_SIZE + VALIDSET_SIZE)\n",
        "val_dataset = train_dataset.skip(TRAINSET_SIZE)\n",
        "train_dataset = train_dataset.take(TRAINSET_SIZE)\n",
        "test_dataset = all_dataset.skip(TRAINSET_SIZE + VALIDSET_SIZE)"
      ],
      "metadata": {
        "id": "fh1Od6UaDrMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate mask over image\n",
        "def weighted_img(img, initial_img, α=1., β=0.5, γ=0.):\n",
        "    return cv2.addWeighted(initial_img, α, img, β, γ)\n",
        "\n",
        "# Function to process an individual image and it's mask\n",
        "def process_image_mask(image, mask):\n",
        "    # Round to closest\n",
        "    mask = tf.math.round(mask)\n",
        "    \n",
        "    # Convert to mask image\n",
        "    zero_image = np.zeros_like(mask)\n",
        "    mask = np.dstack((mask, zero_image, zero_image))\n",
        "    mask = np.asarray(mask, np.float32)\n",
        "    \n",
        "    # Convert to image image\n",
        "    image = np.asarray(image, np.float32)\n",
        "    \n",
        "    # Get the final image\n",
        "    final_image = weighted_img(mask, image)\n",
        "\n",
        "    return final_image"
      ],
      "metadata": {
        "id": "w6rP6rW2Bpwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save predictions\n",
        "def save_predictions(dataset):\n",
        "    # Predict and save image the from input dataset\n",
        "    index = 0\n",
        "    for batch_image, batch_mask in dataset:\n",
        "        for image, mask in zip(batch_image, batch_mask):\n",
        "            print(f\"Processing image : {index}\")\n",
        "            pred_mask = model.predict(tf.expand_dims(image, axis = 0))\n",
        "            save_sample([image, process_image_mask(image, pred_mask[0])], index)\n",
        "            index += 1\n",
        "\n",
        "# Function to save the images as a plot\n",
        "def save_sample(display_list, index):\n",
        "    plt.figure(figsize=(18, 18))\n",
        "\n",
        "    title = ['Input Image', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        plt.axis('off')\n",
        "        \n",
        "    plt.savefig(f\"outputs2/{index}.png\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "zofxSOcsB4B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply Transformations"
      ],
      "metadata": {
        "id": "_NHiSIy3HLGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow function to rescale images to [0, 1]\n",
        "@tf.function\n",
        "def normalize(input_image: tf.Tensor, input_mask: tf.Tensor) -> tuple:\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    return input_image, input_mask\n",
        "\n",
        "# Tensorflow function to apply preprocessing transformations\n",
        "@tf.function\n",
        "def load_image_train(datapoint: dict) -> tuple:\n",
        "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "    return input_image, input_mask\n",
        "\n",
        "# Tensorflow function to preprocess validation images\n",
        "@tf.function\n",
        "def load_image_test(datapoint: dict) -> tuple:\n",
        "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "    return input_image, input_mask"
      ],
      "metadata": {
        "id": "cSBcRwMOEBC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "dataset = {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset}\n",
        "\n",
        "# -- Train Dataset --#\n",
        "dataset['train'] = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset['train'] = dataset['train'].shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
        "dataset['train'] = dataset['train'].repeat()\n",
        "dataset['train'] = dataset['train'].batch(BATCH_SIZE)\n",
        "dataset['train'] = dataset['train'].prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "#-- Validation Dataset --#\n",
        "dataset['val'] = dataset['val'].map(load_image_test)\n",
        "dataset['val'] = dataset['val'].repeat()\n",
        "dataset['val'] = dataset['val'].batch(BATCH_SIZE)\n",
        "dataset['val'] = dataset['val'].prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "#-- Testing Dataset --#\n",
        "dataset['test'] = dataset['test'].map(load_image_test)\n",
        "dataset['test'] = dataset['test'].batch(BATCH_SIZE)\n",
        "dataset['test'] = dataset['test'].prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "print(dataset['train'])\n",
        "print(dataset['val'])\n",
        "print(dataset['test'])"
      ],
      "metadata": {
        "id": "V2AcdbRsECNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test model"
      ],
      "metadata": {
        "id": "kCVNxepYHNos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# os.mkdir(\"outputs2\")\n",
        "save_predictions(dataset['test'])"
      ],
      "metadata": {
        "id": "M051hRICB8Ru"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fully Convolutional Network"
      ],
      "metadata": {
        "id": "6dYHizjfRuXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Debug\n"
      ],
      "metadata": {
        "id": "txRJglxvwLHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "9GzNZ1mhTA5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "id": "5cXNXnv6u5jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device_lib.list_local_devices()"
      ],
      "metadata": {
        "id": "qEBsCgRYvQbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.is_built_with_cuda()"
      ],
      "metadata": {
        "id": "VAxxHhGVvcrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Google drive"
      ],
      "metadata": {
        "id": "nCWkvBfeyvFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "_tjkr7WUyyTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/Shareddrives/'Robotica go brr'/'Lane detection'/FCN\n"
      ],
      "metadata": {
        "id": "BDV3qSDKy76z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "j-ZlkPrFzpa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "NQCEy05DRuXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate \n",
        "from tensorflow.keras.layers import Input, Add, Conv2DTranspose\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanSquaredError, BinaryCrossentropy\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import callbacks\n",
        "\n",
        "from  matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from IPython.display import clear_output\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T04:52:29.348177Z",
          "iopub.execute_input": "2021-10-26T04:52:29.348748Z",
          "iopub.status.idle": "2021-10-26T04:52:29.372591Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.348703Z",
          "shell.execute_reply": "2021-10-26T04:52:29.371925Z"
        },
        "trusted": true,
        "id": "qEkJ8C_nRuXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Source Dataset"
      ],
      "metadata": {
        "id": "Kmd6LQJ3RuXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qxScRVPURuXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load directories\n",
        "train_data_dir = \"input/training/image_2/\"\n",
        "train_gt_dir = \"input/training/gt_image_2/\"\n",
        "\n",
        "test_data_dir = \"input/testing/\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T04:52:29.374385Z",
          "iopub.execute_input": "2021-10-26T04:52:29.374809Z",
          "iopub.status.idle": "2021-10-26T04:52:29.385296Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.374772Z",
          "shell.execute_reply": "2021-10-26T04:52:29.384627Z"
        },
        "trusted": true,
        "id": "y1ZVx-2PRuXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of training examples\n",
        "TRAINSET_SIZE = int(len(os.listdir(train_data_dir)) * 0.8)\n",
        "print(f\"Number of Training Examples: {TRAINSET_SIZE}\")\n",
        "\n",
        "VALIDSET_SIZE = int(len(os.listdir(train_data_dir)) * 0.1)\n",
        "print(f\"Number of Validation Examples: {VALIDSET_SIZE}\")\n",
        "\n",
        "TESTSET_SIZE = int(len(os.listdir(train_data_dir)) - TRAINSET_SIZE - VALIDSET_SIZE)\n",
        "print(f\"Number of Testing Examples: {TESTSET_SIZE}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T04:52:29.386567Z",
          "iopub.execute_input": "2021-10-26T04:52:29.386865Z",
          "iopub.status.idle": "2021-10-26T04:52:29.397555Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.386831Z",
          "shell.execute_reply": "2021-10-26T04:52:29.396473Z"
        },
        "trusted": true,
        "id": "IqygkGK9RuXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Constants\n",
        "IMG_SIZE = 128\n",
        "N_CHANNELS = 3\n",
        "N_CLASSES = 1\n",
        "SEED = 123"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T04:52:29.399573Z",
          "iopub.execute_input": "2021-10-26T04:52:29.400285Z",
          "iopub.status.idle": "2021-10-26T04:52:29.406405Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.40025Z",
          "shell.execute_reply": "2021-10-26T04:52:29.405212Z"
        },
        "trusted": true,
        "id": "35PJZDNtRuXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load image and return a dictionary\n",
        "def parse_image(img_path: str) -> dict:\n",
        "    image = tf.io.read_file(img_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "\n",
        "    # Three types of img paths: um, umm, uu\n",
        "    # gt image paths: um_road, umm_road, uu_road\n",
        "    mask_path = tf.strings.regex_replace(img_path, \"image_2\", \"gt_image_2\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"um_\", \"um_road_\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"umm_\", \"umm_road_\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"uu_\", \"uu_road_\")\n",
        "    \n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=3)\n",
        "    \n",
        "    non_road_label = np.array([255, 0, 0])\n",
        "    road_label = np.array([255, 0, 255])\n",
        "    other_road_label = np.array([0, 0, 0])\n",
        "    \n",
        "    # Convert to mask to binary mask\n",
        "    mask = tf.experimental.numpy.all(mask == road_label, axis = 2)\n",
        "    mask = tf.cast(mask, tf.uint8)\n",
        "    mask = tf.expand_dims(mask, axis=-1)\n",
        "\n",
        "    return {'image': image, 'segmentation_mask': mask}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T04:52:29.407639Z",
          "iopub.execute_input": "2021-10-26T04:52:29.40845Z",
          "iopub.status.idle": "2021-10-26T04:52:29.429158Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.408414Z",
          "shell.execute_reply": "2021-10-26T04:52:29.428492Z"
        },
        "trusted": true,
        "id": "I2j6AKcBRuXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate dataset variables\n",
        "all_dataset = tf.data.Dataset.list_files(train_data_dir + \"*.png\", seed=SEED)\n",
        "all_dataset = all_dataset.map(parse_image)\n",
        "\n",
        "train_dataset = all_dataset.take(TRAINSET_SIZE + VALIDSET_SIZE)\n",
        "val_dataset = train_dataset.skip(TRAINSET_SIZE)\n",
        "train_dataset = train_dataset.take(TRAINSET_SIZE)\n",
        "test_dataset = all_dataset.skip(TRAINSET_SIZE + VALIDSET_SIZE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T04:52:29.431835Z",
          "iopub.execute_input": "2021-10-26T04:52:29.433517Z",
          "iopub.status.idle": "2021-10-26T04:52:29.510632Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.433479Z",
          "shell.execute_reply": "2021-10-26T04:52:29.509767Z"
        },
        "trusted": true,
        "id": "fH3XhJ9fRuXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply Transformations"
      ],
      "metadata": {
        "id": "UqkGSk6NRuXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow function to rescale images to [0, 1]\n",
        "@tf.function\n",
        "def normalize(input_image: tf.Tensor, input_mask: tf.Tensor) -> tuple:\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    return input_image, input_mask\n",
        "\n",
        "# Tensorflow function to apply preprocessing transformations\n",
        "@tf.function\n",
        "def load_image_train(datapoint: dict) -> tuple:\n",
        "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "    return input_image, input_mask\n",
        "\n",
        "# Tensorflow function to preprocess validation images\n",
        "@tf.function\n",
        "def load_image_test(datapoint: dict) -> tuple:\n",
        "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "    return input_image, input_mask"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T04:52:29.515206Z",
          "iopub.execute_input": "2021-10-26T04:52:29.517226Z",
          "iopub.status.idle": "2021-10-26T04:52:29.531209Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.517182Z",
          "shell.execute_reply": "2021-10-26T04:52:29.530443Z"
        },
        "trusted": true,
        "id": "vnZoP1RaRuXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "dataset = {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset}\n",
        "\n",
        "# -- Train Dataset --#\n",
        "dataset['train'] = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "dataset['train'] = dataset['train'].shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
        "dataset['train'] = dataset['train'].repeat()\n",
        "dataset['train'] = dataset['train'].batch(BATCH_SIZE)\n",
        "dataset['train'] = dataset['train'].prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "#-- Validation Dataset --#\n",
        "dataset['val'] = dataset['val'].map(load_image_test)\n",
        "dataset['val'] = dataset['val'].repeat()\n",
        "dataset['val'] = dataset['val'].batch(BATCH_SIZE)\n",
        "dataset['val'] = dataset['val'].prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "#-- Testing Dataset --#\n",
        "dataset['test'] = dataset['test'].map(load_image_test)\n",
        "dataset['test'] = dataset['test'].batch(BATCH_SIZE)\n",
        "dataset['test'] = dataset['test'].prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "print(dataset['train'])\n",
        "print(dataset['val'])\n",
        "print(dataset['test'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T04:52:29.53604Z",
          "iopub.execute_input": "2021-10-26T04:52:29.536432Z",
          "iopub.status.idle": "2021-10-26T04:52:29.739158Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.536397Z",
          "shell.execute_reply": "2021-10-26T04:52:29.738374Z"
        },
        "trusted": true,
        "id": "ipUXa83cRuXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to view the images from the directory\n",
        "def display_sample(display_list):\n",
        "    plt.figure(figsize=(18, 18))\n",
        "\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        plt.axis('off')\n",
        "        \n",
        "    plt.show()\n",
        "    \n",
        "for image, mask in dataset[\"train\"].take(1):\n",
        "    sample_image, sample_mask = image, mask\n",
        "\n",
        "display_sample([sample_image[0], sample_mask[0]])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T04:52:29.740478Z",
          "iopub.execute_input": "2021-10-26T04:52:29.740945Z",
          "iopub.status.idle": "2021-10-26T04:52:43.209188Z",
          "shell.execute_reply.started": "2021-10-26T04:52:29.740906Z",
          "shell.execute_reply": "2021-10-26T04:52:43.208439Z"
        },
        "trusted": true,
        "id": "Cw_zvX7TRuXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Network"
      ],
      "metadata": {
        "id": "_5qeZ1qgRuXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get VGG-16 network as backbone\n",
        "vgg16_model = VGG16()\n",
        "vgg16_model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T04:52:43.210755Z",
          "iopub.execute_input": "2021-10-26T04:52:43.211272Z",
          "iopub.status.idle": "2021-10-26T04:52:45.09499Z",
          "shell.execute_reply.started": "2021-10-26T04:52:43.211235Z",
          "shell.execute_reply": "2021-10-26T04:52:45.09423Z"
        },
        "trusted": true,
        "id": "WBxNdLUtRuXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input shape\n",
        "input_shape = (IMG_SIZE, IMG_SIZE, N_CHANNELS)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T04:52:45.096221Z",
          "iopub.execute_input": "2021-10-26T04:52:45.096464Z",
          "iopub.status.idle": "2021-10-26T04:52:45.102926Z",
          "shell.execute_reply.started": "2021-10-26T04:52:45.096431Z",
          "shell.execute_reply": "2021-10-26T04:52:45.102089Z"
        },
        "trusted": true,
        "id": "B-E0VhFbRuXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a new model using the VGG network\n",
        "# Input\n",
        "inputs = Input(input_shape)\n",
        "\n",
        "# VGG network\n",
        "vgg16_model = VGG16(include_top = False, weights = 'imagenet', input_tensor = inputs)\n",
        "\n",
        "# Encoder Layers\n",
        "c1 = vgg16_model.get_layer(\"block3_pool\").output         \n",
        "c2 = vgg16_model.get_layer(\"block4_pool\").output         \n",
        "c3 = vgg16_model.get_layer(\"block5_pool\").output         \n",
        "\n",
        "# Decoder\n",
        "u1 = UpSampling2D((2, 2), interpolation = 'bilinear')(c3)\n",
        "d1 = Concatenate()([u1, c2])\n",
        "\n",
        "u2 = UpSampling2D((2, 2), interpolation = 'bilinear')(d1)\n",
        "d2 = Concatenate()([u2, c1])\n",
        "\n",
        "# Output\n",
        "u3 = UpSampling2D((8, 8), interpolation = 'bilinear')(d2)\n",
        "outputs = Conv2D(N_CLASSES, 1, activation = 'sigmoid')(u3)\n",
        "\n",
        "model = Model(inputs, outputs, name = \"VGG_FCN8\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:19:55.956499Z",
          "iopub.execute_input": "2021-10-26T05:19:55.957134Z",
          "iopub.status.idle": "2021-10-26T05:19:56.291184Z",
          "shell.execute_reply.started": "2021-10-26T05:19:55.957093Z",
          "shell.execute_reply": "2021-10-26T05:19:56.290407Z"
        },
        "trusted": true,
        "id": "y9bGdHdSRuXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "jCOCUQ1DRuXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Function"
      ],
      "metadata": {
        "id": "5BqNSh__RuXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m_iou = tf.keras.metrics.MeanIoU(2)\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss=BinaryCrossentropy(),\n",
        "              metrics=[m_iou])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:19:59.951931Z",
          "iopub.execute_input": "2021-10-26T05:19:59.95255Z",
          "iopub.status.idle": "2021-10-26T05:19:59.965874Z",
          "shell.execute_reply.started": "2021-10-26T05:19:59.952513Z",
          "shell.execute_reply": "2021-10-26T05:19:59.965013Z"
        },
        "trusted": true,
        "id": "r_JrDQsdRuXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Model"
      ],
      "metadata": {
        "id": "Hqvjmc08RuXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create a mask out of network prediction\n",
        "def create_mask(pred_mask: tf.Tensor) -> tf.Tensor:\n",
        "    # Round to closest\n",
        "    pred_mask = tf.math.round(pred_mask)\n",
        "    \n",
        "    # [IMG_SIZE, IMG_SIZE] -> [IMG_SIZE, IMG_SIZE, 1]\n",
        "    pred_mask = tf.expand_dims(pred_mask, axis=-1)\n",
        "    return pred_mask\n",
        "\n",
        "# Function to show predictions\n",
        "def show_predictions(dataset=None, num=1):\n",
        "    if dataset:\n",
        "        # Predict and show image from input dataset\n",
        "        for image, mask in dataset.take(num):\n",
        "            pred_mask = model.predict(image)\n",
        "            display_sample([image[0], true_mask, create_mask(pred_mask)])\n",
        "    else:\n",
        "        # Predict and show the sample image\n",
        "        inference = model.predict(sample_image)\n",
        "        display_sample([sample_image[0], sample_mask[0],\n",
        "                        inference[0]])\n",
        "        \n",
        "for image, mask in dataset['train'].take(1):\n",
        "    sample_image, sample_mask = image, mask\n",
        "\n",
        "show_predictions()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T04:52:45.449024Z",
          "iopub.execute_input": "2021-10-26T04:52:45.449438Z",
          "iopub.status.idle": "2021-10-26T04:52:58.403903Z",
          "shell.execute_reply.started": "2021-10-26T04:52:45.449403Z",
          "shell.execute_reply": "2021-10-26T04:52:58.403252Z"
        },
        "trusted": true,
        "id": "Df2InaSURuXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ],
      "metadata": {
        "id": "qCZ1oAijRuXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks and Logs\n",
        "class DisplayCallback(callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        clear_output(wait=True)\n",
        "        show_predictions()\n",
        "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
        "\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "callbacks = [\n",
        "    DisplayCallback(),\n",
        "    callbacks.TensorBoard(logdir, histogram_freq = -1),\n",
        "    callbacks.EarlyStopping(patience = 10, verbose = 1),\n",
        "    callbacks.ModelCheckpoint('best_model.h5', verbose = 1, save_best_only = True)\n",
        "]\n",
        "        \n",
        "# Set Variables\n",
        "EPOCHS = 200\n",
        "STEPS_PER_EPOCH = TRAINSET_SIZE // BATCH_SIZE\n",
        "VALIDATION_STEPS = VALIDSET_SIZE // BATCH_SIZE"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T04:52:58.405101Z",
          "iopub.execute_input": "2021-10-26T04:52:58.405497Z",
          "iopub.status.idle": "2021-10-26T04:52:58.711714Z",
          "shell.execute_reply.started": "2021-10-26T04:52:58.40545Z",
          "shell.execute_reply": "2021-10-26T04:52:58.710973Z"
        },
        "trusted": true,
        "id": "12RF2_yRRuXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history = model.fit(dataset['train'], epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          validation_data = dataset[\"val\"],\n",
        "                          validation_steps=VALIDATION_STEPS,\n",
        "                          callbacks = callbacks)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:30:29.765658Z",
          "iopub.execute_input": "2021-10-26T05:30:29.766306Z",
          "iopub.status.idle": "2021-10-26T05:34:19.711077Z",
          "shell.execute_reply.started": "2021-10-26T05:30:29.766267Z",
          "shell.execute_reply": "2021-10-26T05:34:19.707464Z"
        },
        "trusted": true,
        "id": "vZyiNgLFRuXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model\n"
      ],
      "metadata": {
        "id": "vmQQXBpyFyOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(\"saved_model\")\n",
        "model.save('saved_model/my_model')\n",
        "#new_model = tf.keras.models.load_model('saved_model/my_model')"
      ],
      "metadata": {
        "id": "0ABf0ck-AvEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing (Test Dataset)"
      ],
      "metadata": {
        "id": "DJKPWdnQRuXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate mask over image\n",
        "def weighted_img(img, initial_img, α=1., β=0.5, γ=0.):\n",
        "    return cv2.addWeighted(initial_img, α, img, β, γ)\n",
        "\n",
        "# Function to process an individual image and it's mask\n",
        "def process_image_mask(image, mask):\n",
        "    # Round to closest\n",
        "    mask = tf.math.round(mask)\n",
        "    \n",
        "    # Convert to mask image\n",
        "    zero_image = np.zeros_like(mask)\n",
        "    mask = np.dstack((mask, zero_image, zero_image))\n",
        "    mask = np.asarray(mask, np.float32)\n",
        "    \n",
        "    # Convert to image image\n",
        "    image = np.asarray(image, np.float32)\n",
        "    \n",
        "    # Get the final image\n",
        "    final_image = weighted_img(mask, image)\n",
        "\n",
        "    return final_image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:21.597804Z",
          "iopub.execute_input": "2021-10-26T05:04:21.598023Z",
          "iopub.status.idle": "2021-10-26T05:04:21.608255Z",
          "shell.execute_reply.started": "2021-10-26T05:04:21.597997Z",
          "shell.execute_reply": "2021-10-26T05:04:21.607477Z"
        },
        "trusted": true,
        "id": "3ytgM_dORuXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save predictions\n",
        "def save_predictions(dataset):\n",
        "    # Predict and save image the from input dataset\n",
        "    index = 0\n",
        "    for batch_image, batch_mask in dataset:\n",
        "        for image, mask in zip(batch_image, batch_mask):\n",
        "            print(f\"Processing image : {index}\")\n",
        "            pred_mask = model.predict(tf.expand_dims(image, axis = 0))\n",
        "            save_sample([image, process_image_mask(image, pred_mask[0])], index)\n",
        "            index += 1\n",
        "\n",
        "# Function to save the images as a plot\n",
        "def save_sample(display_list, index):\n",
        "    plt.figure(figsize=(18, 18))\n",
        "\n",
        "    title = ['Input Image', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        plt.axis('off')\n",
        "        \n",
        "    plt.savefig(f\"outputs/{index}.png\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:21.609453Z",
          "iopub.execute_input": "2021-10-26T05:04:21.610271Z",
          "iopub.status.idle": "2021-10-26T05:04:21.619483Z",
          "shell.execute_reply.started": "2021-10-26T05:04:21.610245Z",
          "shell.execute_reply": "2021-10-26T05:04:21.618556Z"
        },
        "trusted": true,
        "id": "QoK7iEA7RuXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(\"outputs\")\n",
        "save_predictions(dataset['test'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:21.620659Z",
          "iopub.execute_input": "2021-10-26T05:04:21.620971Z",
          "iopub.status.idle": "2021-10-26T05:04:38.614623Z",
          "shell.execute_reply.started": "2021-10-26T05:04:21.620936Z",
          "shell.execute_reply": "2021-10-26T05:04:38.613957Z"
        },
        "trusted": true,
        "id": "JwTsalwDRuXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing (Videos)"
      ],
      "metadata": {
        "id": "J7k_qEKPRuXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to view video\n",
        "def play(filename):\n",
        "    html = ''\n",
        "    video = open(filename,'rb').read()\n",
        "    src = 'data:video/mp4;base64,' + b64encode(video).decode()\n",
        "    html += '<video width=1000 controls autoplay loop><source src=\"%s\" type=\"video/mp4\"></video>' % src \n",
        "    return HTML(html)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:38.616125Z",
          "iopub.execute_input": "2021-10-26T05:04:38.616913Z",
          "iopub.status.idle": "2021-10-26T05:04:38.622595Z",
          "shell.execute_reply.started": "2021-10-26T05:04:38.616871Z",
          "shell.execute_reply": "2021-10-26T05:04:38.621831Z"
        },
        "trusted": true,
        "id": "1yrgCjO1RuXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process an individual image\n",
        "def process_image(image):\n",
        "    # Preprocess image\n",
        "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    # Get the binary mask\n",
        "    pred_mask = model.predict(np.expand_dims(image, axis = 0))\n",
        "    mask = np.round_(pred_mask[0])\n",
        "    \n",
        "    # Convert to mask image\n",
        "    zero_image = np.zeros_like(mask)\n",
        "    mask = np.dstack((mask, zero_image, zero_image)) * 255\n",
        "    mask = np.asarray(mask, np.uint8)\n",
        "    \n",
        "    # Get the final image\n",
        "    final_image = weighted_img(mask, image)\n",
        "    final_image = cv2.resize(final_image, (1280, 720))\n",
        "\n",
        "    return final_image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:38.623887Z",
          "iopub.execute_input": "2021-10-26T05:04:38.62417Z",
          "iopub.status.idle": "2021-10-26T05:04:38.633198Z",
          "shell.execute_reply.started": "2021-10-26T05:04:38.624136Z",
          "shell.execute_reply": "2021-10-26T05:04:38.632303Z"
        },
        "trusted": true,
        "id": "rAFDvjgeRuXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a new directory\n",
        "os.mkdir(\"videos\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:38.634551Z",
          "iopub.execute_input": "2021-10-26T05:04:38.634829Z",
          "iopub.status.idle": "2021-10-26T05:04:38.643089Z",
          "shell.execute_reply.started": "2021-10-26T05:04:38.634796Z",
          "shell.execute_reply": "2021-10-26T05:04:38.642471Z"
        },
        "trusted": true,
        "id": "tTbQ9_--RuXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project Video"
      ],
      "metadata": {
        "id": "Wq0X7_SeRuXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Creating a VideoCapture object to read the video\n",
        "# project_video = \"project_video.mp4\"\n",
        "# original_video = cv2.VideoCapture(test_data_dir + project_video)\n",
        "# frame_width = int(original_video.get(3))\n",
        "# frame_height = int(original_video.get(4))\n",
        " \n",
        "# # Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
        "# fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
        "# fps = 60\n",
        "# output = cv2.VideoWriter(\"videos/\" + project_video, fourcc, fps, (frame_width,frame_height))\n",
        "\n",
        "# # Process Video\n",
        "# while(original_video.isOpened()):\n",
        "#     ret, frame = original_video.read()\n",
        "\n",
        "#     if ret == True:\n",
        "#         # Write the frame into the file 'output.avi'\n",
        "#         output.write(process_image(frame))\n",
        "\n",
        "#     else:\n",
        "#         break\n",
        "\n",
        "# # When everything done, release the video capture and video write objects\n",
        "# original_video.release()\n",
        "# output.release()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:38.644661Z",
          "iopub.execute_input": "2021-10-26T05:04:38.644923Z",
          "iopub.status.idle": "2021-10-26T05:04:40.920026Z",
          "shell.execute_reply.started": "2021-10-26T05:04:38.644889Z",
          "shell.execute_reply": "2021-10-26T05:04:40.918558Z"
        },
        "trusted": true,
        "id": "sT1ducSiRuXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# play(\"videos/\" + project_video)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:40.9214Z",
          "iopub.status.idle": "2021-10-26T05:04:40.921842Z",
          "shell.execute_reply.started": "2021-10-26T05:04:40.921607Z",
          "shell.execute_reply": "2021-10-26T05:04:40.921631Z"
        },
        "trusted": true,
        "id": "JwrspdmSRuXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge Video"
      ],
      "metadata": {
        "id": "OqwId2jHRuXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Creating a VideoCapture object to read the video\n",
        "# project_video = \"challenge.mp4\"\n",
        "# original_video = cv2.VideoCapture(test_data_dir + project_video)\n",
        "# frame_width = int(original_video.get(3))\n",
        "# frame_height = int(original_video.get(4))\n",
        " \n",
        "# # Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
        "# fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
        "# fps = 60\n",
        "# output = cv2.VideoWriter(\"videos/\" + project_video, fourcc, fps, (frame_width,frame_height))\n",
        "\n",
        "# # Process Video\n",
        "# while(original_video.isOpened()):\n",
        "#     ret, frame = original_video.read()\n",
        "\n",
        "#     if ret == True:\n",
        "#         # Write the frame into the file 'output.avi'\n",
        "#         output.write(process_image(frame))\n",
        "\n",
        "#     else:\n",
        "#         break\n",
        "\n",
        "# # When everything done, release the video capture and video write objects\n",
        "# original_video.release()\n",
        "# output.release()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:40.923182Z",
          "iopub.status.idle": "2021-10-26T05:04:40.92391Z",
          "shell.execute_reply.started": "2021-10-26T05:04:40.923663Z",
          "shell.execute_reply": "2021-10-26T05:04:40.923691Z"
        },
        "trusted": true,
        "id": "gigOnrOXRuXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# play(\"videos/\" + project_video)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:40.925135Z",
          "iopub.status.idle": "2021-10-26T05:04:40.925535Z",
          "shell.execute_reply.started": "2021-10-26T05:04:40.925318Z",
          "shell.execute_reply": "2021-10-26T05:04:40.925339Z"
        },
        "trusted": true,
        "id": "jTOdrJTJRuXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge Video 2"
      ],
      "metadata": {
        "id": "E5YfCkWhRuXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Creating a VideoCapture object to read the video\n",
        "# project_video = \"challenge_video.mp4\"\n",
        "# original_video = cv2.VideoCapture(test_data_dir + project_video)\n",
        "# frame_width = int(original_video.get(3))\n",
        "# frame_height = int(original_video.get(4))\n",
        " \n",
        "# # Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
        "# fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
        "# fps = 60\n",
        "# output = cv2.VideoWriter(\"videos/\" + project_video, fourcc, fps, (frame_width,frame_height))\n",
        "\n",
        "# # Process Video\n",
        "# while(original_video.isOpened()):\n",
        "#     ret, frame = original_video.read()\n",
        "\n",
        "#     if ret == True:\n",
        "#         # Write the frame into the file 'output.avi'\n",
        "#         output.write(process_image(frame))\n",
        "\n",
        "#     else:\n",
        "#         break\n",
        "\n",
        "# # When everything done, release the video capture and video write objects\n",
        "# original_video.release()\n",
        "# output.release()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:40.926891Z",
          "iopub.status.idle": "2021-10-26T05:04:40.927455Z",
          "shell.execute_reply.started": "2021-10-26T05:04:40.927213Z",
          "shell.execute_reply": "2021-10-26T05:04:40.927237Z"
        },
        "trusted": true,
        "id": "_5HrxRyqRuXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# play(\"videos/\" + project_video)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:40.928721Z",
          "iopub.status.idle": "2021-10-26T05:04:40.929275Z",
          "shell.execute_reply.started": "2021-10-26T05:04:40.929037Z",
          "shell.execute_reply": "2021-10-26T05:04:40.929062Z"
        },
        "trusted": true,
        "id": "p0-Wqpm0RuXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Harder Challenge Video"
      ],
      "metadata": {
        "id": "m0t3d_HXRuXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Creating a VideoCapture object to read the video\n",
        "# project_video = \"harder_challenge_video.mp4\"\n",
        "# original_video = cv2.VideoCapture(test_data_dir + project_video)\n",
        "# frame_width = int(original_video.get(3))\n",
        "# frame_height = int(original_video.get(4))\n",
        " \n",
        "# # Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
        "# fourcc = cv2.VideoWriter_fourcc('m','p','4','v')\n",
        "# fps = 60\n",
        "# output = cv2.VideoWriter(\"videos/\" + project_video, fourcc, fps, (frame_width,frame_height))\n",
        "\n",
        "# # Process Video\n",
        "# while(original_video.isOpened()):\n",
        "#     ret, frame = original_video.read()\n",
        "\n",
        "#     if ret == True:\n",
        "#         # Write the frame into the file 'output.avi'\n",
        "#         output.write(process_image(frame))\n",
        "\n",
        "#     else:\n",
        "#         break\n",
        "\n",
        "# # When everything done, release the video capture and video write objects\n",
        "# original_video.release()\n",
        "# output.release()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:40.930547Z",
          "iopub.status.idle": "2021-10-26T05:04:40.931338Z",
          "shell.execute_reply.started": "2021-10-26T05:04:40.931095Z",
          "shell.execute_reply": "2021-10-26T05:04:40.93112Z"
        },
        "trusted": true,
        "id": "bbbukJ0NRuXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# play(\"videos/\" + project_video)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-26T05:04:40.932515Z",
          "iopub.status.idle": "2021-10-26T05:04:40.933315Z",
          "shell.execute_reply.started": "2021-10-26T05:04:40.933072Z",
          "shell.execute_reply": "2021-10-26T05:04:40.933097Z"
        },
        "trusted": true,
        "id": "aDjByGzSRuXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "- [Kitti Dataset Processing](http://ronny.rest/blog/post_2017_09_06_kitti_road_data/)\n",
        "- [Image Segmentation on Keras](https://yann-leguilly.gitlab.io/post/2019-12-14-tensorflow-tfdata-segmentation/)"
      ],
      "metadata": {
        "id": "tKrNkAT0RuXX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "niqHDuWFRuXX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}